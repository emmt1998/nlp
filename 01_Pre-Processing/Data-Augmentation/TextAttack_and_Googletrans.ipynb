{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextAttack and Googletrans.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9OLnhu3dV7ytDQ1nfbLwl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmt1998/nlp/blob/main/01_Pre-Processing/Data-Augmentation/TextAttack_and_Googletrans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUSPoRBEIDAy"
      },
      "source": [
        "Redacted by Efrain Maga√±a emmt1998@gmail.com\r\n",
        "\r\n",
        "Adapted from https://towardsdatascience.com/text-data-augmentation-f4143571ecd2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVbHnAQM5Hh3"
      },
      "source": [
        "# TextAttack\r\n",
        "\r\n",
        "https://github.com/QData/TextAttack\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucxFe-Sw4o5P"
      },
      "source": [
        "!pip install textattack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLjtZqS35R0j"
      },
      "source": [
        "from textattack.augmentation import WordNetAugmenter, EmbeddingAugmenter, EasyDataAugmenter, CharSwapAugmenter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "DDLfO5ya7X-K",
        "outputId": "b2384d7e-0d15-495f-f688-5fa87c738ca6"
      },
      "source": [
        "import pandas as pd\r\n",
        "text1 = \"Understand NLP models better by running different adversarial attacks on them and examining the output\"\r\n",
        "text2 = \"Research and develop different NLP adversarial attacks using the TextAttack framework and library of components\"\r\n",
        "text3 = \"Augment your dataset to increase model generalization and robustness downstream\"\r\n",
        "text =[text1, text2, text3]\r\n",
        "dt = pd.DataFrame(text, columns=[\"text\"])\r\n",
        "dt"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Understand NLP models better by running differ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Research and develop different NLP adversarial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Augment your dataset to increase model general...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  Understand NLP models better by running differ...\n",
              "1  Research and develop different NLP adversarial...\n",
              "2  Augment your dataset to increase model general..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b0Tdjxt95U5r",
        "outputId": "05ed582a-c575-452e-8017-8cc59b4d1b2e"
      },
      "source": [
        "texto = dt['text'][0]\r\n",
        "texto"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Understand NLP models better by running different adversarial attacks on them and examining the output'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRjW4qou5nUS",
        "outputId": "d691bbc3-9f4c-4a3f-d7f2-47b3c70261b6"
      },
      "source": [
        "aug = WordNetAugmenter()\r\n",
        "aug.augment(texto)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Understand NLP models better by running different adversarial onslaught on them and examining the output']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCB2AUqc5pn9",
        "outputId": "270ee555-0a9c-4949-a741-ed3601a58cac"
      },
      "source": [
        "aug = EmbeddingAugmenter()\r\n",
        "aug.augment(texto)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Understand NLP models better by running different adversarial attacks on them and probed the output']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNQMEtSE5qUC",
        "outputId": "d2d5d12d-845e-43f8-f47c-6ab4b7b07fb6"
      },
      "source": [
        "aug = EasyDataAugmenter()\r\n",
        "aug.augment(texto)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Understand NLP models better by running different adversarial attacks on them and examining the unlike output',\n",
              " 'Understand on models better by running different adversarial attacks NLP them and examining the output',\n",
              " 'Understand NLP models sound by running different adversarial attacks on them and examining the output',\n",
              " 'by ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZPXdrQt5t54",
        "outputId": "0c1de377-6447-43c3-cfa6-cfd3fdd1df93"
      },
      "source": [
        "aug = CharSwapAugmenter()\r\n",
        "aug.augment(texto)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Undrstand NLP models better by running different adversarial attacks on them and examining the output']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "gg_mqJPI-tDV",
        "outputId": "8a3f874c-74a2-4ac6-d25a-ddb182e59a25"
      },
      "source": [
        "def augmentationDF(df, colname, aug, only_augmented=False):\r\n",
        "  \"\"\"\r\n",
        "  -> DataFrame\r\n",
        "  \"\"\"\r\n",
        "  textos = df[colname]\r\n",
        "  results = []\r\n",
        "  for i in range(len(textos)):\r\n",
        "    texto = textos[i]\r\n",
        "    result = aug.augment(texto)\r\n",
        "    results = results + result\r\n",
        "  new = pd.DataFrame(results, columns=[colname])\r\n",
        "  if only_augmented:\r\n",
        "    return new\r\n",
        "  else:\r\n",
        "    new = new.append(df, ignore_index=True)\r\n",
        "    return new\r\n",
        "\r\n",
        "def allAug(df, colname, augs, verbose = False):\r\n",
        "  \"\"\"\r\n",
        "  ->DataFrame\r\n",
        "  \"\"\"\r\n",
        "  dtrs = df.copy()\r\n",
        "  for i in range(len(augs)):\r\n",
        "    if verbose:print(\"Augmenter \",i,\"-start\")\r\n",
        "    dtr = augmentationDF(df, colname, augs[i], only_augmented=True)\r\n",
        "    dtrs = dtrs.append(dtr, ignore_index=True)\r\n",
        "    if verbose:print(\"Augmenter \",i,\"-finish\")\r\n",
        "  return dtrs\r\n",
        "\r\n",
        "\r\n",
        "augs = [WordNetAugmenter(), EmbeddingAugmenter(), EasyDataAugmenter(), CharSwapAugmenter()]\r\n",
        "augmented = allAug(dt, \"text\", augs, verbose=True)\r\n",
        "augmented"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenter  0 -start\n",
            "Augmenter  0 -finish\n",
            "Augmenter  1 -start\n",
            "Augmenter  1 -finish\n",
            "Augmenter  2 -start\n",
            "Augmenter  2 -finish\n",
            "Augmenter  3 -start\n",
            "Augmenter  3 -finish\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Understand NLP models better by running differ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Research and develop different NLP adversarial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Augment your dataset to increase model general...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Understand NLP models better by go different a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Research and develop different NLP adversarial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Augment your dataset to increase model inducti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Understand NLP models better by running differ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Research and develop diversified NLP adversari...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Redouble your dataset to increase model genera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>running</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Understand adversarial models better by runnin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Understand NLP models better by running differ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>simulation Understand NLP models better by run...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Research and develop different NLP adversarial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Research and develop different NLP adversarial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>develop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>habituate Research and develop different NLP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Augment your dataset to increase poser general...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Augment your dataset downriver to increase mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Augment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Augment your dataset to increase model and gen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Understand NLP models better by running differ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Resaearch and develop different NLP adversaria...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Augment your dataset to incrYase model general...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text\n",
              "0   Understand NLP models better by running differ...\n",
              "1   Research and develop different NLP adversarial...\n",
              "2   Augment your dataset to increase model general...\n",
              "3   Understand NLP models better by go different a...\n",
              "4   Research and develop different NLP adversarial...\n",
              "5   Augment your dataset to increase model inducti...\n",
              "6   Understand NLP models better by running differ...\n",
              "7   Research and develop diversified NLP adversari...\n",
              "8   Redouble your dataset to increase model genera...\n",
              "9                                            running \n",
              "10  Understand adversarial models better by runnin...\n",
              "11  Understand NLP models better by running differ...\n",
              "12  simulation Understand NLP models better by run...\n",
              "13  Research and develop different NLP adversarial...\n",
              "14  Research and develop different NLP adversarial...\n",
              "15                                           develop \n",
              "16  habituate Research and develop different NLP a...\n",
              "17  Augment your dataset to increase poser general...\n",
              "18  Augment your dataset downriver to increase mod...\n",
              "19                                           Augment \n",
              "20  Augment your dataset to increase model and gen...\n",
              "21  Understand NLP models better by running differ...\n",
              "22  Resaearch and develop different NLP adversaria...\n",
              "23  Augment your dataset to incrYase model general..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekpe3lz1EqBv"
      },
      "source": [
        "# Googletrans\r\n",
        "https://github.com/ssut/py-googletrans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VkhRMxe8b0W"
      },
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjNPDrL6EyJ4"
      },
      "source": [
        "from googletrans import Translator\r\n",
        "translator = Translator()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "GpCs5Bs4FDke",
        "outputId": "4399b14c-1a7a-439e-8315-0de0fdac7e9d"
      },
      "source": [
        "import pandas as pd\r\n",
        "text1 = \"Fast and reliable - it uses the same servers that translate.google.com uses\"\r\n",
        "text2 = \"This uses the Google Translate Ajax API to make calls to such methods as detect and translate.\"\r\n",
        "text3 = \"Googletrans is a free and unlimited python library that implemented Google Translate API\"\r\n",
        "text =[text1, text2, text3]\r\n",
        "dt = pd.DataFrame(text, columns=[\"text\"])\r\n",
        "dt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fast and reliable - it uses the same servers t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This uses the Google Translate Ajax API to mak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Googletrans is a free and unlimited python lib...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  Fast and reliable - it uses the same servers t...\n",
              "1  This uses the Google Translate Ajax API to mak...\n",
              "2  Googletrans is a free and unlimited python lib..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "i3RoyCf-FGKa",
        "outputId": "3f59efc0-f62d-408f-f4ea-e8b146f703c4"
      },
      "source": [
        "texto = dt[\"text\"][0]\r\n",
        "texto"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Fast and reliable - it uses the same servers that translate.google.com uses'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "v-7iKh2qFJxj",
        "outputId": "89da5d85-dbb6-46cc-dad8-f860cc4d268a"
      },
      "source": [
        "# translate from English to Italian\r\n",
        "text_trans = translator.translate(texto, dest='it').text\r\n",
        "text_trans"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Veloce e affidabile: utilizza gli stessi server utilizzati da translate.google.com'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "D-YYunObFfyk",
        "outputId": "dbdcb740-6414-4cd6-f915-082b3448c179"
      },
      "source": [
        "# translate back to Englisht from Italian\r\n",
        "translator.translate(text=text_trans, dest='en').text"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Fast and reliable: use the same servers used by translate.google.com'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "Ix1kmik-Ifry",
        "outputId": "44da76cf-8395-45d9-fe17-3c29afb123bb"
      },
      "source": [
        "def augTrans(text, in_idiom=\"en\", proxy_idiom=\"it\"):\r\n",
        "  \"\"\"\r\n",
        "  -> string\r\n",
        "  \"\"\"\r\n",
        "  text_proxy = translator.translate(text, dest=proxy_idiom).text\r\n",
        "  texto = translator.translate(text_proxy, dest=in_idiom).text\r\n",
        "  return texto\r\n",
        "\r\n",
        "def augmentaDFTrans(df, colname, in_idiom=\"en\", proxy_idiom=\"it\", only_augmented=False):\r\n",
        "  \"\"\"\r\n",
        "  -> DataFrame\r\n",
        "  \"\"\"\r\n",
        "  textos = df[colname]\r\n",
        "  results = []\r\n",
        "  for i in range(len(textos)):\r\n",
        "    texto = textos[i]\r\n",
        "    result = augTrans(texto, in_idiom, proxy_idiom)\r\n",
        "    results.append(result)\r\n",
        "  new = pd.DataFrame(results, columns=[colname])\r\n",
        "  if only_augmented:\r\n",
        "    return new\r\n",
        "  else:\r\n",
        "    new = new.append(df, ignore_index=True)\r\n",
        "    return new\r\n",
        "\r\n",
        "def multipleAugTrans(df, colname, idioms, verbose = False):\r\n",
        "  \"\"\"\r\n",
        "  ->DataFrame\r\n",
        "  \"\"\"\r\n",
        "  dtrs = df.copy()\r\n",
        "  for i in range(1,len(idioms)):\r\n",
        "    if verbose:print(\"Idiom \",i,\"-start\")\r\n",
        "    dtr = augmentaDFTrans(df, colname, in_idiom=idioms[0], proxy_idiom=idioms[i], only_augmented=True)\r\n",
        "    dtrs = dtrs.append(dtr, ignore_index=True)\r\n",
        "    if verbose:print(\"Idiom \",i,\"-finish\")\r\n",
        "  return dtrs\r\n",
        "\r\n",
        "\r\n",
        "idioms = [\"en\", \"it\", \"es\", \"fr\", \"zh-cn\"]\r\n",
        "augmented = multipleAugTrans(dt, \"text\", idioms, verbose = True)\r\n",
        "augmented\r\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Idiom  1 -start\n",
            "Idiom  1 -finish\n",
            "Idiom  2 -start\n",
            "Idiom  2 -finish\n",
            "Idiom  3 -start\n",
            "Idiom  3 -finish\n",
            "Idiom  4 -start\n",
            "Idiom  4 -finish\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fast and reliable - it uses the same servers t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This uses the Google Translate Ajax API to mak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Googletrans is a free and unlimited python lib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fast and reliable: use the same servers used b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This uses Google Translate's Ajax API to make ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Googletrans is a free and unlimited Python lib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Fast and reliable: uses the same servers that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This uses the Google Translate Ajax API to mak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Googletrans is a free and unlimited Python lib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Fast and reliable - it uses the same servers a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>This uses the Google Translate Ajax API to cal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Googletrans is a free and unlimited Python lib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Fast and reliable-it uses the same server as t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>This uses the Google Translate Ajax API to cal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Googletrans is a free and unrestricted python ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text\n",
              "0   Fast and reliable - it uses the same servers t...\n",
              "1   This uses the Google Translate Ajax API to mak...\n",
              "2   Googletrans is a free and unlimited python lib...\n",
              "3   Fast and reliable: use the same servers used b...\n",
              "4   This uses Google Translate's Ajax API to make ...\n",
              "5   Googletrans is a free and unlimited Python lib...\n",
              "6   Fast and reliable: uses the same servers that ...\n",
              "7   This uses the Google Translate Ajax API to mak...\n",
              "8   Googletrans is a free and unlimited Python lib...\n",
              "9   Fast and reliable - it uses the same servers a...\n",
              "10  This uses the Google Translate Ajax API to cal...\n",
              "11  Googletrans is a free and unlimited Python lib...\n",
              "12  Fast and reliable-it uses the same server as t...\n",
              "13  This uses the Google Translate Ajax API to cal...\n",
              "14  Googletrans is a free and unrestricted python ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYkXXkZnJg5g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}